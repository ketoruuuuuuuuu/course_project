{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cianparser\n",
    "# import pandas as pd\n",
    "import requests\n",
    "# from bs4 import BeautifulSoup\n",
    "import cloudscraper\n",
    "# from datetime import datetime\n",
    "# import pytz\n",
    "import time\n",
    "import random\n",
    "# from datetime import timedelta\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "from tqdm import trange, tqdm\n",
    "from IPython import display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "replace(',','.') для площадей (done)\n",
    "\n",
    "вывод времени на ожидание (done)\n",
    "\n",
    "лок на 15 картинок (done)\n",
    "\n",
    "починить высоту потолков (done, but need to check)\n",
    "\n",
    "сделать одну жирную функцию, которая сразу сохраняет csv\n",
    "\n",
    "попробовать поставить билиотеку вручную и исправить сити нейборс на то, что бы искало или добавить в список городов айди ленобласти (done)\n",
    "\n",
    "оптимизировать процесс сбора фоток, наверное сократить до 10 + убрать/уменьшить паузу на сбор инфы вцелом(done)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "scraper = cloudscraper.create_scraper()\n",
    "scraper.headers = {'Accept-Language': 'en'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_offer(scraper,url):\n",
    "    status = 1\n",
    "    page = scraper.get(url)\n",
    "    soup = BeautifulSoup(page.text, \"html.parser\")\n",
    "    if soup.text.find(\"Captcha\") > 0:\n",
    "            print('Капча')\n",
    "            status = 0\n",
    "    elif soup.text.find('Объявление снято с публикации') > 0:\n",
    "          print('Объявление снято с публикации')\n",
    "          status = 0\n",
    "    elif page.status_code == 200:\n",
    "          print('Страница получена')\n",
    "    else:\n",
    "          print('Что-то пошло не так ({})'.format(page.status_code)) \n",
    "          status = 0 \n",
    "    return soup,status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_date_of_post(soup):\n",
    "    date_offer_full = soup.find('div',class_ = \"a10a3f92e9--item--qLmCs\").find('span')\n",
    "    date_offer_full = date_offer_full.text\n",
    "    date_offer = date_offer_full[date_offer_full.find(':')+2:]\n",
    "    now = datetime.now(pytz.timezone('Europe/Moscow'))\n",
    "    date_list = date_offer.split(',')\n",
    "    if date_list[0] == 'вчера':\n",
    "        vchera = now - timedelta(days=1)\n",
    "        vchera = vchera.strftime(\"%d/%m/%Y\")\n",
    "        date_list[0] = vchera\n",
    "    elif date_list[0] == 'сегодня':\n",
    "        today = now.strftime(\"%d/%m/%Y\")\n",
    "        date_list[0] = today\n",
    "    else:\n",
    "        date_0 = date_list[0].split(' ')\n",
    "        if date_0[1] == 'ноя':\n",
    "            date_0 = '{}/11/2023'.format(date_0[0])\n",
    "            date_list[0] = date_0\n",
    "        if date_0[1] == 'дек':\n",
    "            date_0 = '{}/12/2023'.format(date_0[0])\n",
    "            date_list[0] = date_0\n",
    "        if date_0[1] == 'янв':\n",
    "            date_0 = '{}/1/2024'.format(date_0[0])\n",
    "            date_list[0] = date_0\n",
    "        if date_0[1] == 'фев':\n",
    "            date_0 = '{}/2/2024'.format(date_0[0])\n",
    "            date_list[0] = date_0\n",
    "    date_offer = ' '.join(date_list)\n",
    "    return(date_offer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "about_flat_info = 'a10a3f92e9--color_black_100--Ephi7 a10a3f92e9--lineHeight_6u--cedXD a10a3f92e9--fontWeight_normal--JEG_c a10a3f92e9--fontSize_16px--QNYmt a10a3f92e9--display_block--KYb25 a10a3f92e9--text--e4SBY a10a3f92e9--text_letterSpacing__0--cQxU5'\n",
    "about_flat_type_info = 'a10a3f92e9--color_gray60_100--mYFjS a10a3f92e9--lineHeight_6u--cedXD a10a3f92e9--fontWeight_normal--JEG_c a10a3f92e9--fontSize_16px--QNYmt a10a3f92e9--display_block--KYb25 a10a3f92e9--text--e4SBY a10a3f92e9--text_letterSpacing__0--cQxU5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HOUSE_INFO = ['Жилая площадь','Площадь кухни','Высота потолков','Планировка','Санузел','Балкон/лоджия','Вид из окон','Ремонт','Год постройки','Тип дома','Аварийность','Парковка']\n",
    "len(HOUSE_INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_house_info(soup,house_info_dict,i):\n",
    "    len_home_info = len(soup.select('div[data-name=\"OfferSummaryInfoItem\"]'))\n",
    "    temp_info_dict = {}\n",
    "    for h in range(len_home_info):\n",
    "        type_info = soup.select('div[data-name=\"OfferSummaryInfoItem\"]')[h].find('span', class_ = about_flat_type_info).text\n",
    "        info = soup.select('div[data-name=\"OfferSummaryInfoItem\"]')[h].find('span', class_ = about_flat_info).text\n",
    "        if info != 'Нет информации' and type_info != 'Общая площадь':\n",
    "            if type_info == 'Высота потолков':\n",
    "                 if info.find(',') != -1:\n",
    "                    info = info[0] + '.' + info[2]\n",
    "                 else:\n",
    "                     info = info[0]\n",
    "            if type_info in ['Жилая площадь','Площадь кухни']:\n",
    "                info = info.replace(',','.')\n",
    "            if type_info == 'Санузел':\n",
    "                 if info.find(',') != -1:\n",
    "                    toilet = info.split(',')\n",
    "                    info = int(toilet[0][0]) + int(toilet[1][1])\n",
    "                 else:\n",
    "                    info = int(info[0])\n",
    "            temp_info_dict[type_info] = info\n",
    "        # print('{}: {}'.format(type_info,info))\n",
    "    for key in list(temp_info_dict.keys()):\n",
    "            if key in HOUSE_INFO:\n",
    "                house_info_dict[key][i] = temp_info_dict[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FEATURES = ['Холодильник','Стиральная машина','Телевизор','Ванна','Мебель на кухне','Посудомоечная машина','Кондиционер','Интернет','Душевая кабина','Мебель в комнатах']\n",
    "len(FEATURES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(soup,features_dict,i):\n",
    "    features = soup.select('div[data-name=\"FeaturesItem\"]')\n",
    "    for f in features:\n",
    "        features_dict[f.text][i] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in [0,0,0,2,1,4]:\n",
    "#     try:\n",
    "#         ans = 5/i\n",
    "#         break\n",
    "#     except ZeroDivisionError:\n",
    "#         pass\n",
    "\n",
    "# print(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_photos(soup, id_):\n",
    "    photos = soup.select('img[data-name=\"ThumbComponent\"]')\n",
    "    len_photos = len(photos)\n",
    "    if len_photos > 10:\n",
    "        len_photos = 10\n",
    "    for i in trange(len_photos, desc= 'photos', colour= 'CYAN'):\n",
    "        ph_link = photos[i].get('src')\n",
    "        ph_link = ph_link[:-5] + '1' +ph_link[-4:]\n",
    "        for i in range(5):\n",
    "            try:\n",
    "                r = scraper.get(ph_link)\n",
    "                im = Image.open(BytesIO(r.content))\n",
    "                im = im.resize((300,300), Image.LANCZOS)\n",
    "                im.save('photos/{}_{}.jpg'.format(id_,i))\n",
    "            except ConnectionError:\n",
    "                time.sleep(3)\n",
    "                pass\n",
    "        # im = Image.open(BytesIO(r.content))\n",
    "        # im = im.resize((300,300), Image.LANCZOS)\n",
    "        # im.save('photos/{}_{}.jpg'.format(id_,i))\n",
    "        rnd = 3*random.random()\n",
    "        time.sleep(5+rnd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_h_dict(links):\n",
    "    house_info_dict = {}\n",
    "    house_info_dict['id'] = [0 for i in range(len(links))]\n",
    "    for item in HOUSE_INFO:\n",
    "        house_info_dict[item] = [None for i in range(len(links))]\n",
    "    return(house_info_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_f_dict(links):\n",
    "    features_dict = {}\n",
    "    features_dict['id'] = [0 for i in range(len(links))]\n",
    "    for item in FEATURES:\n",
    "        features_dict[item] = [0 for i in range(len(links))]\n",
    "    return(features_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_new_df(data):\n",
    "    df2 = pd.DataFrame(data)\n",
    "    df2['underground'] = df2['underground'].apply(lambda x: None if x == '' else x)\n",
    "    df2 = df2.drop(['author','author_type','deal_type','commissions','accommodation_type'],axis = 1)\n",
    "    try:\n",
    "        df2 = df2.drop('residential_complex', axis = 1)\n",
    "    except KeyError:\n",
    "        pass\n",
    "    return(df2)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_old_df(LOCATION,ROOM):\n",
    "    if LOCATION == 'Ленобласть':\n",
    "        city = 'LEN_OBL'\n",
    "    else:\n",
    "        city = 'SPB'\n",
    "    df_old = pd.read_csv('cian_data_r_{}_c_{}.csv'.format(ROOM,city),index_col=0)\n",
    "    return(df_old,city)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_dfs(df_old,df2):\n",
    "    links = df2['link']\n",
    "    links_to_drop = []\n",
    "    curr_time = datetime.now(pytz.timezone('Europe/Moscow')).strftime(\"%d/%m/%Y %H:%M\")\n",
    "    for i in range(len(links)):\n",
    "        url = links[i]\n",
    "        old_links = list(df_old['link'])\n",
    "        if url in old_links:\n",
    "            if df_old[df_old['link'] == url]['price_per_month'].item() == df2['price_per_month'][i].item():\n",
    "                df_old.loc[df_old['link'] == url,'time_parse'] = curr_time\n",
    "                links_to_drop.append(url)\n",
    "            else: \n",
    "                df_old = df_old.drop(df_old[df_old['link'] == url].index, axis = 0).reset_index(drop = True)\n",
    "    df2 = df2.drop(df2[df2['link'].isin(links_to_drop)].index, axis = 0).reset_index(drop = True)\n",
    "    print('Объявлений уже в данных: {}'.format(len(links_to_drop)))\n",
    "    return df_old, df2\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROOMS = ['studio',1,2,3,4,5]\n",
    "ROOMS = [1,2,3,4,5]\n",
    "LOCATIONS = ['Санкт-Петербург','Ленобласть']\n",
    "# LOCATIONS = ['Ленобласть']\n",
    "ADD_SETTINGS = {'sort_by' :'creation_data_from_newer_to_older'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "начать с двойки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                              Preparing to collect information from pages..\n",
      "The page from which the collection of information begins: \n",
      " https://cian.ru/cat.php?engine_version=2&p=1&region=2&offer_type=flat&deal_type=rent&room1=1&with_neighbors=0&type=4&sort=creation_date_desc\n",
      "Collecting information from pages with list of announcements\n",
      " 1 | 1 page with list: [=>=>=>=>=>=>=>=>=>=>=>=>=>=>=>=>=>=>=>=>=>=>=>=>=>=>=>=>] 100% | Count of all parsed: 28. Progress ratio: 100 %. Average price: 36 142 rub\r"
     ]
    }
   ],
   "source": [
    "#GIGA_MEGA_PARSE\n",
    "for LOCATION in LOCATIONS:\n",
    "    for ROOM in ROOMS:\n",
    "        for page in range(1,20): #55 MAX\n",
    "            display.clear_output(wait=False)\n",
    "            data = cianparser.parse(deal_type=\"rent_long\",accommodation_type=\"flat\",location=LOCATION,rooms=ROOM,additional_settings=ADD_SETTINGS,\n",
    "            start_page=page,\n",
    "            end_page=page)\n",
    "\n",
    "            #скип цикла, если страницы кончились\n",
    "            if len(data) == 0:\n",
    "                continue\n",
    "            df2 = create_new_df(data)\n",
    "            print('Найдено объявлений: {}'.format(len(df2)))\n",
    "            df_old, city = get_old_df(LOCATION,ROOM)\n",
    "            df_old, df2 = update_dfs(df_old,df2)    \n",
    "            links = df2['link']\n",
    "            print('Объявлений на обработку: {}'.format(len(links)))\n",
    "            house_info_dict = create_h_dict(links)\n",
    "            features_dict = create_f_dict(links)\n",
    "            ids_ = []\n",
    "            date_info = []\n",
    "            time_parse = []\n",
    "\n",
    "            for i in range(len(links)):\n",
    "                print('-'*20,'{} | {}'.format(ROOM,city),'-'*20) \n",
    "                url = links[i]\n",
    "                print('{}/{} '.format(i+1,len(links)),url)\n",
    "                id_ = url.split('/')[-2]\n",
    "                ids_.append(id_)\n",
    "                scraper = cloudscraper.create_scraper()\n",
    "                rnd_name = random.choice(['dasha','masha','tosha','sasha','vasya','kolya','anna','fedya','bob','mark','grisha'])\n",
    "                rnd_dig = random.randint(100,9000)\n",
    "                scraper.headers = {'Accept-Language': 'en','User-Agent': '{}{}@gmail.com'.format(rnd_name,rnd_dig)}\n",
    "                soup, satatus = parse_offer(scraper,url)\n",
    "                #скип цикла, если страница не алё\n",
    "                if satatus == 0:\n",
    "                    date_info.append(0)\n",
    "                    time_parse.append(0)\n",
    "                    continue\n",
    "                with tqdm(total=3,desc = 'info', colour = 'CYAN') as pbar:\n",
    "                    date_offer = get_date_of_post(soup)\n",
    "                    date_info.append(date_offer)\n",
    "                    time_parse.append(datetime.now(pytz.timezone('Europe/Moscow')).strftime(\"%d/%m/%Y %H:%M\"))\n",
    "                    pbar.update(1)\n",
    "                    get_house_info(soup,house_info_dict,i)\n",
    "                    house_info_dict['id'][i] = id_\n",
    "                    pbar.update(1)\n",
    "                    get_features(soup,features_dict,i)\n",
    "                    features_dict['id'][i] = id_\n",
    "                    pbar.update(1)\n",
    "                get_photos(soup,id_)\n",
    "                rnd = 3*random.random()\n",
    "                time.sleep(5+rnd)\n",
    "                \n",
    "            \n",
    "            df_h = pd.DataFrame(house_info_dict)\n",
    "            df_f = pd.DataFrame(features_dict)\n",
    "            df2.insert(0,'id',ids_)\n",
    "            df2.insert(1,'time_post',date_info)\n",
    "            df2.insert(2,'time_parse',time_parse)\n",
    "            df3_j1 = df2.join(df_f.set_index('id'),on = 'id')\n",
    "            df3_j2 = df3_j1.join(df_h.set_index('id'),on = 'id')\n",
    "            df4 = pd.concat([df_old,df3_j2]).reset_index(drop = True)\n",
    "            df4.to_csv('cian_data_r_{}_c_{}.csv'.format(ROOM,city))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Объявление снято с публикации\n"
     ]
    }
   ],
   "source": [
    "# soup,status =  parse_offer(scraper,'https://spb.cian.ru/rent/flat/295015271/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                              Preparing to collect information from pages..\n",
      "The page from which the collection of information begins: \n",
      " https://cian.ru/cat.php?engine_version=2&p=1&region=2&offer_type=flat&deal_type=rent&room1=1&with_neighbors=0&type=4&sort=creation_date_desc\n",
      "Collecting information from pages with list of announcements\n",
      " 1 | 1 page with list: [=>=>=>=>=>=>=>=>=>=>=>=>=>=>=>=>=>=>=>=>=>=>=>=>=>=>=>=>] 100% | Count of all parsed: 28. Progress ratio: 100 %. Average price: 32 428 rub\n",
      "\n",
      "The collection of information from the pages with list of announcements is completed\n",
      "Total number of parsed announcements: 28. Average price per month: 32 428 rub\n",
      "\n",
      "Найдено объявлений: 28\n",
      "Объявлений уже в данных: 0\n",
      "Объявлений на обработку: 28\n",
      "-------------------- 1 | SPB --------------------\n",
      "1/28  https://spb.cian.ru/rent/flat/295883550/\n",
      "Страница получена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "info: 100%|██████████| 3/3 [00:00<00:00, 15.15it/s]\n",
      "photos: 0it [00:00, ?it/s]\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# #GIGA_MEGA_PARSE\n",
    "# for LOCATION in LOCATIONS:\n",
    "#     for ROOM in ROOMS:\n",
    "        \n",
    "#         data = cianparser.parse(deal_type=\"rent_long\",accommodation_type=\"flat\",location=LOCATION,rooms=ROOM,additional_settings=ADD_SETTINGS,\n",
    "#         start_page=1,\n",
    "#         end_page=1)\n",
    "\n",
    "#         df2 = create_new_df(data)\n",
    "#         print('Найдено объявлений: {}'.format(len(df2)))\n",
    "#         df_old, city = get_old_df(LOCATION,ROOM)\n",
    "#         df_old, df2 = update_dfs(df_old,df2)    \n",
    "#         links = df2['link']\n",
    "#         print('Объявлений на обработку: {}'.format(len(links)))\n",
    "#         house_info_dict = create_h_dict(links)\n",
    "#         features_dict = create_f_dict(links)\n",
    "#         ids_ = []\n",
    "#         date_info = []\n",
    "#         time_parse = []\n",
    "\n",
    "#         for i in range(len(links)):\n",
    "#             print('-'*20,'{} | {}'.format(ROOM,city),'-'*20) # попробовать 12\n",
    "#             url = links[i]\n",
    "#             print('{}/{} '.format(i+1,len(links)),url)\n",
    "#             id_ = url.split('/')[-2]\n",
    "#             ids_.append(id_)\n",
    "#             soup, satatus = parse_offer(scraper,url)\n",
    "#             if satatus == 0:\n",
    "#                 continue\n",
    "#             with tqdm(total=3,desc = 'info') as pbar:\n",
    "#                 date_offer = get_date_of_post(soup)\n",
    "#                 date_info.append(date_offer)\n",
    "#                 time_parse.append(datetime.now(pytz.timezone('Europe/Moscow')).strftime(\"%d/%m/%Y %H:%M\"))\n",
    "#                 pbar.update(1)\n",
    "#                 get_house_info(soup,house_info_dict,i)\n",
    "#                 house_info_dict['id'][i] = id_\n",
    "#                 pbar.update(1)\n",
    "#                 get_features(soup,features_dict,i)\n",
    "#                 features_dict['id'][i] = id_\n",
    "#                 pbar.update(1)\n",
    "#             get_photos(soup,id_)\n",
    "#             rnd = 3*random.random()\n",
    "#             time.sleep(5+rnd)\n",
    "            \n",
    "        \n",
    "#         df_h = pd.DataFrame(house_info_dict)\n",
    "#         df_f = pd.DataFrame(features_dict)\n",
    "#         df2.insert(0,'id',ids_)\n",
    "#         df2.insert(1,'time_post',date_info)\n",
    "#         df2.insert(2,'time_parse',time_parse)\n",
    "#         df3_j1 = df2.join(df_f.set_index('id'),on = 'id')\n",
    "#         df3_j2 = df3_j1.join(df_h.set_index('id'),on = 'id')\n",
    "#         df4 = pd.concat([df_old,df3_j2]).reset_index(drop = True)\n",
    "#         df4.to_csv('cian_data_r_{}_c_{}.csv'.format(ROOM,city))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "timing - примерно обьявление в минуту"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\ntsec\\Desktop\\jup_projects_1\\course_project\\cain_data_collector_almost_fin.ipynb Cell 21\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/ntsec/Desktop/jup_projects_1/course_project/cain_data_collector_almost_fin.ipynb#X26sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m a \u001b[39m=\u001b[39m \u001b[39m1\u001b[39;49m\u001b[39m/\u001b[39;49m\u001b[39m0\u001b[39;49m\n",
      "\u001b[1;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "a = 1/0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = cianparser.parse(\n",
    "#     deal_type=\"rent_long\",\n",
    "#     accommodation_type=\"flat\",\n",
    "#     location=LOCATION,\n",
    "#     rooms=ROOM,\n",
    "#     start_page=1,\n",
    "#     end_page=4,\n",
    "#     additional_settings={'sort_by' :'creation_data_from_newer_to_older'}\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df2 = pd.DataFrame(data)\n",
    "# print(len(df2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df2['underground'] = df2['underground'].apply(lambda x: None if x == '' else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df2 = df2.drop(['author','author_type','deal_type','commissions','accommodation_type'],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if LOCATION == 'Ленобласть':\n",
    "#     CITY = 'LEN_OBL'\n",
    "# else:\n",
    "#     CITY = 'SPB'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_old = pd.read_csv('cian_data_r_{}_c_{}.csv'.format(ROOM,CITY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# links = df2['link']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1', '3', '4']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a = ['1','2','3','4']\n",
    "# a.pop(1)\n",
    "# a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ids_ = []\n",
    "# links_to_drop = []\n",
    "# curr_time = datetime.now(pytz.timezone('Europe/Moscow')).strftime(\"%d/%m/%Y %H:%M\")\n",
    "# for i in range(len(links)):\n",
    "#     url = links[i]\n",
    "#     id_ = url.split('/')[-2]\n",
    "#     if id_ in df_old['id']:\n",
    "#         if df_old[df_old['id'] == id_]['price'] == df2['price'][i]:\n",
    "#             df_old[df_old['id'] == id_]['time_parse'] = curr_time\n",
    "#             links_to_drop.append(i)\n",
    "#         else: \n",
    "#             df = df_old.drop(df_old[df_old['id'] == id_], axis = 0)\n",
    "# links = links.drop(links_to_drop,axis = 0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# house_info_dict = {}\n",
    "# house_info_dict['id'] = [0 for i in range(len(links))]\n",
    "# for item in HOUSE_INFO:\n",
    "#     house_info_dict[item] = [None for i in range(len(links))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features_dict = {}\n",
    "# features_dict['id'] = [0 for i in range(len(links))]\n",
    "# for item in FEATURES:\n",
    "#     features_dict[item] = [0 for i in range(len(links))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ids_ = []\n",
    "# date_info = []\n",
    "# time_parse = []\n",
    "# for i in range(len(links)):\n",
    "#     url = links[i]\n",
    "#     print('{}/{} '.format(i+1,len(links)),url)\n",
    "#     id_ = url.split('/')[-2]\n",
    "#     ids_.append(id_)\n",
    "#     soup = parse_offer(scraper,url)\n",
    "#     with tqdm(total=3,desc = 'info') as pbar:\n",
    "#         date_offer = get_date_of_post(soup)\n",
    "#         date_info.append(date_offer)\n",
    "#         time_parse.append(datetime.now(pytz.timezone('Europe/Moscow')).strftime(\"%d/%m/%Y %H:%M\"))\n",
    "#         pbar.update(1)\n",
    "#         get_house_info(soup,house_info_dict,i)\n",
    "#         house_info_dict['id'][i] = id_\n",
    "#         pbar.update(1)\n",
    "#         get_features(soup,features_dict,i)\n",
    "#         features_dict['id'][i] = id_\n",
    "#         pbar.update(1)\n",
    "#     get_photos(soup,id_)\n",
    "#     rnd = 3*random.random()\n",
    "#     time.sleep(5+rnd)\n",
    "#     print('------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_h = pd.DataFrame(house_info_dict)\n",
    "# df_h.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_f = pd.DataFrame(features_dict)\n",
    "# df_f.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df2.insert(0,'id',ids_)\n",
    "# df2.insert(1,'time_post',date_info)\n",
    "# df2.insert(2,'time_parse',time_parse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df3_j1 = df2.join(df_f.set_index('id'),on = 'id')\n",
    "# df3_j1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df3_j2 = df3_j1.join(df_h.set_index('id'),on = 'id')\n",
    "# df3_j2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_time = datetime.now(pytz.timezone('Europe/Moscow')).strftime(\"%d-%m-%Y_%H-%M\")\n",
    "# df3_j2.to_csv('cian_data_r_{}_d_{}.csv'.format(ROOM,save_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "new_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
